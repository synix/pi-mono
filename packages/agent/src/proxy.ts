/**
 * Proxy stream function for apps that route LLM calls through a server.
 * The server manages auth and proxies requests to LLM providers.
 */

// Internal import for JSON parsing utility
import {
	type AssistantMessage,
	type AssistantMessageEvent,
	type Context,
	EventStream,
	type Model,
	parseStreamingJson,
	type SimpleStreamOptions,
	type StopReason,
	type ToolCall,
} from "@mariozechner/pi-ai";

// ğŸš€ å®ç°äº†proxy(ä»£ç†)æ¨¡å¼

// å¯¹æ¯” packages/ai/src/utils/event-stream.ts ä¸­çš„ AssistantMessageEventStream

// Create stream class matching ProxyMessageEventStream
class ProxyMessageEventStream extends EventStream<AssistantMessageEvent, AssistantMessage> {
	constructor() {
		super(
			(event) => event.type === "done" || event.type === "error",
			(event) => {
				if (event.type === "done") return event.message;
				if (event.type === "error") return event.error;
				throw new Error("Unexpected event type");
			},
		);
	}
}

/*
	å¯¹æ¯” packages/ai/src/types.ts ä¸­çš„ AssistantMessageEvent
	æ ¸å¿ƒåŒºåˆ«å°±ä¸€ä¸ª: ProxyAssistantMessageEvent å»æ‰äº†æ‰€æœ‰ partial å­—æ®µ
	æ¯ä¸ªäº‹ä»¶éƒ½å°‘äº† partial (ç´¯ç§¯çš„å®Œæ•´æ¶ˆæ¯å¿«ç…§), è¿™æ˜¯å¸¦å®½ä¼˜åŒ– â€” partial æ˜¯ä¸€ä¸ªä¸æ–­å¢é•¿çš„å¯¹è±¡, æ¯ä¸ª deltaäº‹ä»¶éƒ½å¸¦ä¸Šå®Œæ•´å¿«ç…§ä¼šé€ æˆå¤§é‡é‡å¤ä¼ è¾“

	å®¢æˆ·ç«¯æ”¶åˆ° ProxyAssistantMessageEvent åï¼Œé€šè¿‡ä¸‹é¢çš„ processProxyEvent() å‡½æ•°åœ¨æœ¬åœ°ç»´æŠ¤ä¸€ä¸ª partial å¯¹è±¡ï¼ŒæŠŠ delta é€æ­¥æ‹¼æ¥ä¸Šå»ï¼Œé‡å»ºå‡ºå®Œæ•´çš„ AssistantMessageEvent:

	æœåŠ¡ç«¯                          ç½‘ç»œ                          å®¢æˆ·ç«¯
  AssistantMessageEvent    â†’   å»æ‰ partial    â†’    ProxyAssistantMessageEvent
  (å¸¦ partial å¿«ç…§)             èŠ‚çœå¸¦å®½              æ”¶åˆ°åæœ¬åœ°é‡å»º partial
                                                           â†“
                                                    processProxyEvent()
                                                    æ‹¼æ¥ delta åˆ°æœ¬åœ° partial
                                                           â†“
                                                    è¿˜åŸä¸º AssistantMessageEvent

	å¦å¤–è¿˜æœ‰ä¸¤ä¸ªå°å·®å¼‚ï¼š
		- text_end / thinking_endï¼šåŸç‰ˆå¸¦ content: stringï¼ˆå®Œæ•´æ–‡æœ¬ï¼‰ï¼Œä»£ç†ç‰ˆåªå¸¦å¯é€‰çš„ contentSignature
		- toolcall_startï¼šåŸç‰ˆåªæœ‰ contentIndex + partialï¼Œä»£ç†ç‰ˆé¢å¤–ä¼ äº† id å’Œ toolNameï¼ˆå› ä¸ºæ²¡æœ‰ partialï¼Œå®¢æˆ·ç«¯éœ€è¦è¿™äº›ä¿¡æ¯æ¥åˆå§‹åŒ– toolCall å¯¹è±¡ï¼‰
		- doneï¼šåŸç‰ˆå¸¦ message: AssistantMessageï¼ˆå®Œæ•´æ¶ˆæ¯ï¼‰ï¼Œä»£ç†ç‰ˆåªå¸¦ usageï¼ˆå®¢æˆ·ç«¯å·²ç»è‡ªå·±æ‹¼å‡ºäº†å®Œæ•´æ¶ˆæ¯ï¼‰

*/

/**
 * Proxy event types - server sends these with partial field stripped to reduce bandwidth.
 */
export type ProxyAssistantMessageEvent =
	| { type: "start" }
	| { type: "text_start"; contentIndex: number }
	| { type: "text_delta"; contentIndex: number; delta: string }
	| { type: "text_end"; contentIndex: number; contentSignature?: string }
	| { type: "thinking_start"; contentIndex: number }
	| { type: "thinking_delta"; contentIndex: number; delta: string }
	| { type: "thinking_end"; contentIndex: number; contentSignature?: string }
	| { type: "toolcall_start"; contentIndex: number; id: string; toolName: string }
	| { type: "toolcall_delta"; contentIndex: number; delta: string }
	| { type: "toolcall_end"; contentIndex: number }
	| {
			type: "done";
			reason: Extract<StopReason, "stop" | "length" | "toolUse">;
			usage: AssistantMessage["usage"];
	  }
	| {
			type: "error";
			reason: Extract<StopReason, "aborted" | "error">;
			errorMessage?: string;
			usage: AssistantMessage["usage"];
	  };

export interface ProxyStreamOptions extends SimpleStreamOptions {
	/** Auth token for the proxy server */
	authToken: string;
	/** Proxy server URL (e.g., "https://genai.example.com") */
	proxyUrl: string;
}

/**
 * Stream function that proxies through a server instead of calling LLM providers directly.
 * The server strips the partial field from delta events to reduce bandwidth.
 * We reconstruct the partial message client-side.
 *
 * Use this as the `streamFn` option when creating an Agent that needs to go through a proxy.
 *
 * @example
 * ```typescript
 * const agent = new Agent({
 *   streamFn: (model, context, options) =>
 *     streamProxy(model, context, {
 *       ...options,
 *       authToken: await getAuthToken(),
 *       proxyUrl: "https://genai.example.com",
 *     }),
 * });
 * ```
 */
export function streamProxy(model: Model<any>, context: Context, options: ProxyStreamOptions): ProxyMessageEventStream {
	const stream = new ProxyMessageEventStream();

	(async () => {
		// Initialize the partial message that we'll build up from events
		const partial: AssistantMessage = {
			role: "assistant",
			stopReason: "stop",
			content: [],
			api: model.api,
			provider: model.provider,
			model: model.id,
			usage: {
				input: 0,
				output: 0,
				cacheRead: 0,
				cacheWrite: 0,
				totalTokens: 0,
				cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0, total: 0 },
			},
			timestamp: Date.now(),
		};

		let reader: ReadableStreamDefaultReader<Uint8Array> | undefined;

		const abortHandler = () => {
			if (reader) {
				reader.cancel("Request aborted by user").catch(() => {});
			}
		};

		if (options.signal) {
			options.signal.addEventListener("abort", abortHandler);
		}

		try {
			// `${options.proxyUrl}/api/stream` æœåŠ¡ç«¯endpointçš„èŒè´£æ˜¯:
			// æ¥æ”¶è¿™ä¸ªè¯·æ±‚ï¼Œç”¨è‡ªå·±çš„ API key å»è°ƒç”¨çœŸæ­£çš„ LLM(Anthropic/OpenAI ç­‰), æŠŠ LLMè¿”å›çš„æµå¼äº‹ä»¶å‰¥ç¦» partial å­—æ®µå, ä»¥ SSE æ ¼å¼è½¬å‘å›æ¥
			const response = await fetch(`${options.proxyUrl}/api/stream`, {
				method: "POST",
				headers: {
					Authorization: `Bearer ${options.authToken}`,
					"Content-Type": "application/json",
				},
				body: JSON.stringify({
					model,
					context,
					options: {
						temperature: options.temperature,
						maxTokens: options.maxTokens,
						reasoning: options.reasoning,
					},
				}),
				signal: options.signal,
			});

			if (!response.ok) {
				let errorMessage = `Proxy error: ${response.status} ${response.statusText}`;
				try {
					const errorData = (await response.json()) as { error?: string };
					if (errorData.error) {
						errorMessage = `Proxy error: ${errorData.error}`;
					}
				} catch {
					// Couldn't parse error response
				}
				throw new Error(errorMessage);
			}

			reader = response.body!.getReader();
			const decoder = new TextDecoder();
			let buffer = "";

			while (true) {
				const { done, value } = await reader.read();
				if (done) break;

				if (options.signal?.aborted) {
					throw new Error("Request aborted by user");
				}

				buffer += decoder.decode(value, { stream: true });
				const lines = buffer.split("\n");
				buffer = lines.pop() || "";

				for (const line of lines) {
					if (line.startsWith("data: ")) {
						const data = line.slice(6).trim();
						if (data) {
							const proxyEvent = JSON.parse(data) as ProxyAssistantMessageEvent;
							// å°† ProxyAssistantMessageEvent å¤åŸæˆ AssistantMessageEventï¼Œå¹¶æ›´æ–° partial
							const event = processProxyEvent(proxyEvent, partial);
							if (event) {
								stream.push(event);
							}
						}
					}
				}
			}

			if (options.signal?.aborted) {
				throw new Error("Request aborted by user");
			}

			stream.end();
		} catch (error) {
			const errorMessage = error instanceof Error ? error.message : String(error);
			const reason = options.signal?.aborted ? "aborted" : "error";
			partial.stopReason = reason;
			partial.errorMessage = errorMessage;
			stream.push({
				type: "error",
				reason,
				error: partial,
			});
			stream.end();
		} finally {
			if (options.signal) {
				options.signal.removeEventListener("abort", abortHandler);
			}
		}
	})();

	return stream;
}

/**
 * Process a proxy event and update the partial message.
 */
function processProxyEvent(
	proxyEvent: ProxyAssistantMessageEvent,
	partial: AssistantMessage,
): AssistantMessageEvent | undefined {
	switch (proxyEvent.type) {
		case "start":
			return { type: "start", partial };

		case "text_start":
			partial.content[proxyEvent.contentIndex] = { type: "text", text: "" };
			return { type: "text_start", contentIndex: proxyEvent.contentIndex, partial };

		case "text_delta": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "text") {
				content.text += proxyEvent.delta;
				return {
					type: "text_delta",
					contentIndex: proxyEvent.contentIndex,
					delta: proxyEvent.delta,
					partial,
				};
			}
			throw new Error("Received text_delta for non-text content");
		}

		case "text_end": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "text") {
				content.textSignature = proxyEvent.contentSignature;
				return {
					type: "text_end",
					contentIndex: proxyEvent.contentIndex,
					content: content.text,
					partial,
				};
			}
			throw new Error("Received text_end for non-text content");
		}

		case "thinking_start":
			partial.content[proxyEvent.contentIndex] = { type: "thinking", thinking: "" };
			return { type: "thinking_start", contentIndex: proxyEvent.contentIndex, partial };

		case "thinking_delta": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "thinking") {
				content.thinking += proxyEvent.delta;
				return {
					type: "thinking_delta",
					contentIndex: proxyEvent.contentIndex,
					delta: proxyEvent.delta,
					partial,
				};
			}
			throw new Error("Received thinking_delta for non-thinking content");
		}

		case "thinking_end": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "thinking") {
				content.thinkingSignature = proxyEvent.contentSignature;
				return {
					type: "thinking_end",
					contentIndex: proxyEvent.contentIndex,
					content: content.thinking,
					partial,
				};
			}
			throw new Error("Received thinking_end for non-thinking content");
		}

		case "toolcall_start":
			partial.content[proxyEvent.contentIndex] = {
				type: "toolCall",
				id: proxyEvent.id,
				name: proxyEvent.toolName,
				arguments: {},
				partialJson: "",
			} satisfies ToolCall & { partialJson: string } as ToolCall;
			return { type: "toolcall_start", contentIndex: proxyEvent.contentIndex, partial };

		case "toolcall_delta": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "toolCall") {
				(content as any).partialJson += proxyEvent.delta;
				// å·¥å…·å‚æ•°çš„å¢é‡é‡å»º
				content.arguments = parseStreamingJson((content as any).partialJson) || {};
				partial.content[proxyEvent.contentIndex] = { ...content }; // Trigger reactivity
				return {
					type: "toolcall_delta",
					contentIndex: proxyEvent.contentIndex,
					delta: proxyEvent.delta,
					partial,
				};
			}
			throw new Error("Received toolcall_delta for non-toolCall content");
		}

		case "toolcall_end": {
			const content = partial.content[proxyEvent.contentIndex];
			if (content?.type === "toolCall") {
				delete (content as any).partialJson;
				return {
					type: "toolcall_end",
					contentIndex: proxyEvent.contentIndex,
					toolCall: content,
					partial,
				};
			}
			return undefined;
		}

		case "done":
			partial.stopReason = proxyEvent.reason;
			partial.usage = proxyEvent.usage;
			return { type: "done", reason: proxyEvent.reason, message: partial };

		case "error":
			partial.stopReason = proxyEvent.reason;
			partial.errorMessage = proxyEvent.errorMessage;
			partial.usage = proxyEvent.usage;
			return { type: "error", reason: proxyEvent.reason, error: partial };

		default: {
			const _exhaustiveCheck: never = proxyEvent;
			console.warn(`Unhandled proxy event type: ${(proxyEvent as any).type}`);
			return undefined;
		}
	}
}
